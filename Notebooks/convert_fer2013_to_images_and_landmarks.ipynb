{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Extraction of facial features\n"],"metadata":{"id":"gaUw_bsNYfCr"}},{"cell_type":"markdown","source":["## Initializing and installation of packages"],"metadata":{"id":"xaQclO_-Yn6U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gHls6AKXuTR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680896004672,"user_tz":-120,"elapsed":2132,"user":{"displayName":"Marta Borràs Duarte","userId":"04271369017031645060"}},"outputId":"1dc385c2-3298-463d-a3a8-f99d1aad2642"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Import packages.\n","import numpy as np\n","import pandas as pd\n","import os\n","import errno\n","import dlib\n","import cv2\n","import imageio\n","import skimage\n","\n","from skimage.feature import hog\n","from imageio import imsave"],"metadata":{"id":"ZYfeblDLZOks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check Python and packages' version.\n","!python3 --version\n","print(\"numpy: \"+np.__version__)\n","print(\"pandas: \"+pd.__version__)\n","print(\"dlib: \"+dlib.__version__)\n","print(\"opencv: \"+cv2.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5b-wsE17kpPr","executionInfo":{"status":"ok","timestamp":1680896004673,"user_tz":-120,"elapsed":13,"user":{"displayName":"Marta Borràs Duarte","userId":"04271369017031645060"}},"outputId":"51e55999-86a4-4979-d643-113db2decbfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.9.16\n","numpy: 1.22.4\n","pandas: 1.4.4\n","dlib: 19.24.1\n","opencv: 4.7.0\n"]}]},{"cell_type":"code","source":["# Initialization of variables: Chose the value of the variables to be entered.\n","image_height = 48\n","image_width = 48\n","window_size = 24\n","window_step = 6\n","ONE_HOT_ENCODING = False\n","SAVE_IMAGES = False\n","GET_LANDMARKS = False\n","GET_HOG_FEATURES = True\n","GET_HOG_WINDOWS_FEATURES = False\n","SELECTED_LABELS = [0,1,2,3,4,5,6]\n","IMAGES_PER_LABEL = 40000 # Use the entire dataset.\n","OUTPUT_FOLDER_NAME = \"/content/drive/MyDrive/TFG_FER/Extracted_Features/fer2013plus_hog\""],"metadata":{"id":"aN3kq8bRZhQU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load dataset"],"metadata":{"id":"31kY6RG3p-Cz"}},{"cell_type":"code","source":["!unzip \"Dlib.zip\" # If not yet done."],"metadata":{"id":"fFHnHniKk8tP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679986566408,"user_tz":-120,"elapsed":2707,"user":{"displayName":"Marta Borràs Duarte","userId":"04271369017031645060"}},"outputId":"91f4bb71-1dc4-428b-96a7-e5b47d72b226"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  Dlib.zip\n","  inflating: shape_predictor_68_face_landmarks.dat  \n"]}]},{"cell_type":"code","source":["# Load Dlib predictor and prepare arrays.\n","predictor = dlib.shape_predictor('/content/drive/MyDrive/TFG_FER/Datasets_and_packages/shape_predictor_68_face_landmarks.dat') # Predictor of facial landmarks from dlib library.\n","original_labels = [0, 1, 2, 3, 4, 5, 6]\n","new_labels = list(set(original_labels) & set(SELECTED_LABELS)) # New labels will only contain the unique elements (set) that are present in both 'original_labels' and'SELECTED_LABELS'.\n","nb_images_per_label = list(np.zeros(len(new_labels), 'uint8')) # Creates a new list of uint8 data that has the same length as 'new_labels' and is filled with zeros, which will later be\n","                                                               # used to keep track of the number of images belonging to each label."],"metadata":{"id":"Uzlj8Zj_aHlU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a new directory to store facial features.\n","%cd /content/drive/MyDrive/TFG_FER/Extracted_Features/\n","try:\n","    os.makedirs(OUTPUT_FOLDER_NAME) # Create new directory with the name specified in 'OUTPUT_FOLDER_NAME'.\n","except OSError as e: # Exception if an error 'e' occurs.\n","    if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME): # If the directory altready exists ('EEXIST') and it is, in fact, a directory, the action is passed.\n","        pass\n","    else:\n","        raise # If there is any other kind of error, rises an error."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsvZncD1lrTu","executionInfo":{"status":"ok","timestamp":1680898170367,"user_tz":-120,"elapsed":6,"user":{"displayName":"Marta Borràs Duarte","userId":"04271369017031645060"}},"outputId":"1b8ac7c2-b717-43a9-c3df-01b3b1c965a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/TFG_FER/Extracted_Features\n"]}]},{"cell_type":"markdown","source":["## Definition of functions"],"metadata":{"id":"HIYY-rgQZpPy"}},{"cell_type":"code","source":["# Definition of function to get facial landmarks.\n","def get_landmarks(image, rects): # 'rects' is a list of rectangles (window of face detected).\n","    if len(rects) > 1: # If there is more than one face detected, the function rises a message indicating there are too many faces detected (only one detection at the time).\n","        raise BaseException(\"TooManyFaces\")\n","    if len(rects) == 0: # If no faces have been detected, the function rises a message indicating no faces have been detected.\n","        raise BaseException(\"NoFaces\")\n","    return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()]) # If only one face has been detected, the 'predictor' function is used to obtain a set of facial landmarks\n","                                                                               # for the face within the given image. The landmarks are returned as a numpy matrix, where each row represents a\n","                                                                               # landmark point and has two columns for the x and y coordinates."],"metadata":{"id":"q0hjVzPhmhL6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Explanation of **'np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])'**:\n","\n","The 'predictor' function is called on the input image and the first rectangle in the 'rects' list, which is assumed to contain the face of interest. The 'parts()' method is called on the result of the 'predictor' function, which returns a set of landmarks detected by the facial landmark detector.\n","\n","The resulting set of landmarks is then used to create a two-dimensional NumPy array using a list comprehension. For each landmark point 'p' in the set, a list of its x and y coordinates '([p.x, p.y])' is created. These lists are then grouped together into a larger list that contains all the landmarks in the set.\n","\n","The resulting list of landmark coordinates is then converted into a NumPy matrix using the 'np.matrix()' function. The resulting matrix has dimensions '(n,2)', where n is the number of landmarks detected in the input image. The first column of the matrix contains the x-coordinates of the landmarks, and the second column contains the y-coordinates.\n"],"metadata":{"id":"PuLKQXNu9a9T"}},{"cell_type":"code","source":["# Definition of function to convert a label from its original form to a new label that is compatible with a particular ML model.\n","def get_new_label(label, one_hot_encoding=False): # 'label' is the original label, and 'one_hot_encoding' is a bool that indicates whether to use one-hot-encoding for the new label.\n","    if one_hot_encoding:\n","        new_label = new_labels.index(label) # 'new_label' is the index (position) of the original label ('label') in the 'new_labels' list.\n","        label = list(np.zeros(len(new_labels), 'uint8')) # Creates a numpy list of zeros with the same length as 'new_labels'.\n","        label[new_label] = 1 # Fills the position of the new label with a 1, to create the one_hot_encoding.\n","        return label\n","    else:\n","        return new_labels.index(label)"],"metadata":{"id":"ANPxN6Ivm0i0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definition of function to apply the HOG algorithm on a sliding window basis.\n","def sliding_hog_windows(image):\n","    hog_windows = [] # The 'hog_windows' list will contain the HOG descriptors of each sliding window in the image.\n","    for y in range(0, image_height, window_step): # Slide in the y axis.\n","        for x in range(0, image_width, window_step): # Slide in the x axis.\n","            window = image[y:y+window_size, x:x+window_size] # Definition of the size of the window.\n","            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), visualize=False)) # Use '.extend()' instead of '.append()' to add the hog values array individually.\n","    return hog_windows"],"metadata":{"id":"qnbegaYLnBkn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import dataset"],"metadata":{"id":"SpxJRDQeS68V"}},{"cell_type":"code","source":["# Unzip fer2013.csv.zip if not done already.\n","%cd /content/drive/MyDrive/TFG_FER/\n","!unzip '/content/drive/MyDrive/TFG_FER/Datasets_and_packages/fer2013.csv.zip'"],"metadata":{"id":"WWDLqIrIBPKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the fer2013.csv which contains the FER2013 dataset.\n","data = pd.read_csv('/content/drive/MyDrive/TFG_FER/Datasets_and_packages/fer2013plus.csv')"],"metadata":{"id":"G4E_wE7wnIcs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Converting FER2013 to images and landmarks"],"metadata":{"id":"avRKfmeaS-ZL"}},{"cell_type":"code","source":["for category in data['Usage'].unique(): # For each unique 'Usage' column ('Training', 'PublicTest' and 'PrivateTest') in fer2013.csv...\n","\n","    print( \"Converting set: \" + category + \"...\") # To track where the conversion process is currently at.\n","\n","    # Create a folder for each category.\n","    if not os.path.exists(category): # If there is not a directory with the same name as the category, create a folder.\n","        try:\n","            os.makedirs(OUTPUT_FOLDER_NAME + '/' + category) # The folder is created in the specified path.\n","        except OSError as e:\n","            if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n","               pass\n","            else:\n","                raise\n","\n","    # Get samples and labels of each category.\n","    category_data = data[data['Usage'] == category] # 'data['Usage'] == category' creates a boolean mask that filters the rows of data where the value in the 'Usage' column matches category.\n","                                                    # 'data[data['Usage'] == category]' returns a new DataFrame of data that includes only the rows that match the mask created in the\n","                                                    # previous step.\n","    samples = category_data['pixels'].values # Extracts the pixel data (from the 'pixel' row) of each image in the category and returns them as a NumPy array.\n","    labels = category_data['emotion'].values # Extracts the corresponding emotion label (from the 'emotion' row) of each image in the category and returns them as a NumPy array.\n","\n","    # Get images and extract features.\n","    images = []\n","    labels_list = []\n","    landmarks = []\n","    hog_features = []\n","    hog_images = []\n","    for i in range(len(samples)): # For all the positions of images...\n","        try:\n","            if labels[i] in SELECTED_LABELS and nb_images_per_label[get_new_label(labels[i])] < IMAGES_PER_LABEL: # If the label of that image is in 'SELECTED_LABELS' and the number\n","                                                                                                                  # images for that label is inferior to 'IMAGES_PER_LABEL'...\n","                image = np.fromstring(samples[i], dtype=int, sep=\" \").reshape((image_height, image_width)) # 'samples[i]' is a string representing a flattened image, where each\n","                                                                                                           # pixel's value is separated by a space.\n","                                                                                                           # 'np.fromstring(samples[i], dtype=int, sep=\" \") creates a 1D numpy array\n","                                                                                                           # of integers from the string, where each pixel's value becomes an element in the array.\n","                                                                                                           # '.reshape((image_height, image_width)) reshapes the 1D array into a 2D numpy array\n","                                                                                                           # of shape (image_height, image_width)'.\n","\n","                images.append(image)\n","                if SAVE_IMAGES: # 'SAVES_IMAGES' = True\n","                    image_uin8 = image.astype(np.uint8)\n","                    imsave(category + '/' + str(i) + '.jpg', image_uin8)\n","                if GET_HOG_WINDOWS_FEATURES: # 'GET_HOG_WINDOWS_FEATURES' = True\n","                    features = sliding_hog_windows(image)\n","                    f, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n","                    hog_features.append(features)\n","                    hog_images.append(hog_image)\n","                elif GET_HOG_FEATURES: # 'GET_HOG_FEATURES' = True\n","                    features, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n","                    hog_features.append(features)\n","                    hog_images.append(hog_image)\n","                if GET_LANDMARKS: # 'GET_LANDMARKS' = True\n","                    image_uin8 = image.astype(np.uint8)\n","                    imsave('temp.jpg', image_uin8) # The temp.jpg file is used in the code as a temporary file to store the image data in jpeg format. The reason for saving the image to a file is so that it can be\n","                                                   # loaded by the cv2 library, which is used to apply facial landmark detection using the dlib library. The cv2.imread() function can only load image data from a file\n","                                                   # on disk, so the temporary file is used to provide the image data to the function. Once the facial landmark detection is complete, the temporary file is no longer\n","                                                   # needed and can be deleted.\n","                    image2 = cv2.imread('temp.jpg')\n","                    face_rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)] # Draws a 47x47 rectangle (it is not detecting the face).\n","                    face_landmarks = get_landmarks(image2, face_rects)\n","                    landmarks.append(face_landmarks)\n","\n","                labels_list.append(get_new_label(labels[i], one_hot_encoding=ONE_HOT_ENCODING)) # Appends the integer label or its one-hot encoded representation (based on the one_hot_encoding parameter) to the labels_list.\n","                                                                                                # 'labels_list' is a list that stores the integer labels for each image.\n","                nb_images_per_label[get_new_label(labels[i])] += 1 # += 1 updates the count of images processed for the corresponding integer label in the nb_images_per_label dictionary.\n","\n","        # Errors.\n","        except Exception as e:\n","            print( \"error in image: \" + str(i) + \" - \" + str(e))\n","\n","    np.save(OUTPUT_FOLDER_NAME + '/' + category + '/images.npy', images)\n","    if ONE_HOT_ENCODING:\n","        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n","    else:\n","        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n","    if GET_LANDMARKS:\n","        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/landmarks.npy', landmarks)\n","    if GET_HOG_FEATURES or GET_HOG_WINDOWS_FEATURES:\n","        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/hog_features.npy', hog_features)\n","        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/hog_images.npy', hog_images)\n"],"metadata":{"id":"4wcONKelnYhP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680898264800,"user_tz":-120,"elapsed":89721,"user":{"displayName":"Marta Borràs Duarte","userId":"04271369017031645060"}},"outputId":"88b8cf74-055d-406f-e94d-832ec0754365"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converting set: Training...\n","Converting set: PublicTest...\n","Converting set: PrivateTest...\n"]}]},{"cell_type":"markdown","source":["## Bibliography\n","https://github.com/amineHorseman/facial-expression-recognition-svm/blob/master/convert_fer2013_to_images_and_landmarks.py"],"metadata":{"id":"w2C0dRy7HzSa"}}]}